{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import os\n",
    "import fastai\n",
    "from fastai.text import *\n",
    "from fastai import *\n",
    "import regex as re\n",
    "import spacy\n",
    "from fastai.text.core import tokenize_texts \n",
    "import collections \n",
    "from collections import Counter\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start distillation from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the teacher ground truth (used for distillation loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_labels = np.loadtxt('teacher_labels.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07070994, 0.40288487, 0.32499784, ..., 0.11287053, 0.16063896,\n",
       "       0.1547837 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the student for training (potamias model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the roberta tokenizer and model \n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\"\n",
    "roberta_model = roberta_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"train_8k.csv\")\n",
    "df_valid = pd.read_csv(\"test_4k.csv\")\n",
    "df_trial = pd.read_csv(\"trial_1k.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old id</th>\n",
       "      <th>new id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>int_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>472189928340606976</td>\n",
       "      <td>519632796449378304</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472440774785650688</td>\n",
       "      <td>519632825167773696</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473085653454827520</td>\n",
       "      <td>519632853982650370</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>463445012374499328</td>\n",
       "      <td>519632882940129280</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>463501257110724610</td>\n",
       "      <td>519632911473987584</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               old id              new id  label  \\\n",
       "0  472189928340606976  519632796449378304  -3.99   \n",
       "1  472440774785650688  519632825167773696  -3.92   \n",
       "2  473085653454827520  519632853982650370  -2.22   \n",
       "3  463445012374499328  519632882940129280  -0.56   \n",
       "4  463501257110724610  519632911473987584  -1.27   \n",
       "\n",
       "                                                                                                                          text  \\\n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT   \n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony   \n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not   \n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end   \n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm   \n",
       "\n",
       "   int_label  \n",
       "0         -4  \n",
       "1         -4  \n",
       "2         -2  \n",
       "3         -1  \n",
       "4         -1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7985, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = ['old id', 'new id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3    2966\n",
       "-2    2931\n",
       "-1     860\n",
       "-4     363\n",
       " 0     344\n",
       " 2     195\n",
       " 1     163\n",
       " 3     106\n",
       " 4      49\n",
       "-5       6\n",
       " 5       2\n",
       "Name: int_label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['int_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns={'int_label': 'label'}, inplace=True)\n",
    "df_train = df_train[[\"label\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4</td>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4</td>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2</td>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0     -4   \n",
       "1     -4   \n",
       "2     -2   \n",
       "3     -1   \n",
       "4     -1   \n",
       "\n",
       "                                                                                                                          text  \n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT  \n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony  \n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not  \n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end  \n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.376513e+17</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.383325e+17</td>\n",
       "      <td>-2</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.380508e+17</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>@KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.380175e+17</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>@stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.379588e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  label category  \\\n",
       "0  5.376513e+17     -3  sarcasm   \n",
       "1  5.383325e+17     -2  sarcasm   \n",
       "2  5.380508e+17     -3  sarcasm   \n",
       "3  5.380175e+17     -3  sarcasm   \n",
       "4  5.379588e+17      0  sarcasm   \n",
       "\n",
       "                                                                                                                                          text  \n",
       "0                          So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED  \n",
       "1                          If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm  \n",
       "2  @KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT  \n",
       "3                                                              @stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not  \n",
       "4                                                    Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = df_valid.drop(columns = ['id', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>int_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465424601124974592</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>RT @BeckyMyers3: General studies exam tomorrow and I have about as much common sense and knowledge as a peanut</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>465422141643845632</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>RT @TheTweetOfGod: A racist NBA owner makes about as much sense as a homophobic theater producer.</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>465420676590231552</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>Bit ironic Mo Farrah stars in the Weetabix advert when he shares about as much personality as a semi chipped bowl filled with half of one</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465420343344394240</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>@JoshFreedman_ It is about as much an election than Katie Price was a singer.</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465414678978756609</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>Just looked out the window. About as inviting as a tour of Karbul. Today is that day i 'finally' polyfilled that hole in the bathroom! Brb</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  label  \\\n",
       "0  465424601124974592   -3.0   \n",
       "1  465422141643845632   -3.4   \n",
       "2  465420676590231552   -2.8   \n",
       "3  465420343344394240   -2.8   \n",
       "4  465414678978756609   -2.4   \n",
       "\n",
       "                                                                                                                                         text  \\\n",
       "0                              RT @BeckyMyers3: General studies exam tomorrow and I have about as much common sense and knowledge as a peanut   \n",
       "1                                           RT @TheTweetOfGod: A racist NBA owner makes about as much sense as a homophobic theater producer.   \n",
       "2   Bit ironic Mo Farrah stars in the Weetabix advert when he shares about as much personality as a semi chipped bowl filled with half of one   \n",
       "3                                                               @JoshFreedman_ It is about as much an election than Katie Price was a singer.   \n",
       "4  Just looked out the window. About as inviting as a tour of Karbul. Today is that day i 'finally' polyfilled that hole in the bathroom! Brb   \n",
       "\n",
       "   int_label  \n",
       "0         -3  \n",
       "1         -3  \n",
       "2         -3  \n",
       "3         -3  \n",
       "4         -2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df_trial.drop(columns = ['id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial.rename(columns={'int_label': 'label'}, inplace=True)\n",
    "df_trial = df_trial[[\"label\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7985, 2), (592, 2), (3957, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_trial.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, df_trial], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8577, 2), (3957, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4</td>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4</td>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2</td>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0     -4   \n",
       "1     -4   \n",
       "2     -2   \n",
       "3     -1   \n",
       "4     -1   \n",
       "\n",
       "                                                                                                                          text  \n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT  \n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony  \n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not  \n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end  \n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3</td>\n",
       "      <td>So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2</td>\n",
       "      <td>If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3</td>\n",
       "      <td>@KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3</td>\n",
       "      <td>@stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0     -3   \n",
       "1     -2   \n",
       "2     -3   \n",
       "3     -3   \n",
       "4      0   \n",
       "\n",
       "                                                                                                                                          text  \n",
       "0                          So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED  \n",
       "1                          If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm  \n",
       "2  @KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT  \n",
       "3                                                              @stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not  \n",
       "4                                                    Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "myle = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = myle.fit_transform(df_train['label'])\n",
    "\n",
    "df_valid['label'] = myle.fit_transform(df_valid['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     3191\n",
       "3     3067\n",
       "4      925\n",
       "1      410\n",
       "5      377\n",
       "7      218\n",
       "6      196\n",
       "8      126\n",
       "9       56\n",
       "0        8\n",
       "10       3\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     1530\n",
       "2      730\n",
       "4      671\n",
       "5      293\n",
       "8      201\n",
       "6      164\n",
       "7      150\n",
       "9      111\n",
       "1       99\n",
       "10       4\n",
       "0        4\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = df_train['text']\n",
    "tweets_valid = df_valid['text']\n",
    "\n",
    "tweets_train = tweets_train.tolist()\n",
    "tweets_valid = tweets_valid.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenizer(tweets_train, truncation=True)\n",
    "tokens_valid = tokenizer(tweets_valid, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tokens'] = tokens_train['input_ids']\n",
    "df_valid['tokens'] = tokens_valid['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8577.000000\n",
       "mean       29.213361\n",
       "std        10.932552\n",
       "min         8.000000\n",
       "25%        22.000000\n",
       "50%        28.000000\n",
       "75%        35.000000\n",
       "max       512.000000\n",
       "Name: n_tok, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['n_tok'] = df_train['tokens'].apply(len)\n",
    "df_valid['n_tok'] = df_valid['tokens'].apply(len)\n",
    "\n",
    "df_train['n_tok'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "      <td>[0, 100, 95, 657, 447, 13, 231, 4, 245, 722, 396, 10, 1108, 50, 932, 4, 17570, 77, 38, 437, 15, 127, 675, 8, 33, 11522, 3977, 9782, 4, 849, 37049, 2]</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "      <td>[0, 133, 1372, 2214, 473, 45, 32550, 205, 6453, 4, 85, 18, 888, 1341, 2778, 19887, 4, 849, 853, 6119, 2]</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "      <td>[0, 15852, 7, 422, 7, 5, 2341, 78, 631, 11, 5, 662, 16, 10, 372, 169, 7, 386, 5, 183, 849, 3654, 2]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "      <td>[0, 1039, 673, 119, 5107, 25786, 40237, 46116, 197, 33, 56, 849, 29, 9636, 16836, 23, 5, 253, 2]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "      <td>[0, 30327, 2283, 13, 209, 94, 367, 360, 9, 334, 8, 960, 14, 16, 164, 7, 28, 528, 328, 849, 29, 9636, 16836, 2]</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      3   \n",
       "3      4   \n",
       "4      4   \n",
       "\n",
       "                                                                                                                          text  \\\n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT   \n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony   \n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not   \n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end   \n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm   \n",
       "\n",
       "                                                                                                                                                  tokens  \\\n",
       "0  [0, 100, 95, 657, 447, 13, 231, 4, 245, 722, 396, 10, 1108, 50, 932, 4, 17570, 77, 38, 437, 15, 127, 675, 8, 33, 11522, 3977, 9782, 4, 849, 37049, 2]   \n",
       "1                                               [0, 133, 1372, 2214, 473, 45, 32550, 205, 6453, 4, 85, 18, 888, 1341, 2778, 19887, 4, 849, 853, 6119, 2]   \n",
       "2                                                    [0, 15852, 7, 422, 7, 5, 2341, 78, 631, 11, 5, 662, 16, 10, 372, 169, 7, 386, 5, 183, 849, 3654, 2]   \n",
       "3                                                       [0, 1039, 673, 119, 5107, 25786, 40237, 46116, 197, 33, 56, 849, 29, 9636, 16836, 23, 5, 253, 2]   \n",
       "4                                         [0, 30327, 2283, 13, 209, 94, 367, 360, 9, 334, 8, 960, 14, 16, 164, 7, 28, 528, 328, 849, 29, 9636, 16836, 2]   \n",
       "\n",
       "   n_tok  \n",
       "0     32  \n",
       "1     21  \n",
       "2     23  \n",
       "3     19  \n",
       "4     24  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(teacher_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_labels = pd.Series(teacher_labels)\n",
    "\n",
    "df_train['teacher_labels'] = teacher_labels\n",
    "df_valid['teacher_labels'] = teacher_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "      <th>teacher_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "      <td>[0, 100, 95, 657, 447, 13, 231, 4, 245, 722, 396, 10, 1108, 50, 932, 4, 17570, 77, 38, 437, 15, 127, 675, 8, 33, 11522, 3977, 9782, 4, 849, 37049, 2]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.070710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "      <td>[0, 133, 1372, 2214, 473, 45, 32550, 205, 6453, 4, 85, 18, 888, 1341, 2778, 19887, 4, 849, 853, 6119, 2]</td>\n",
       "      <td>21</td>\n",
       "      <td>0.402885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "      <td>[0, 15852, 7, 422, 7, 5, 2341, 78, 631, 11, 5, 662, 16, 10, 372, 169, 7, 386, 5, 183, 849, 3654, 2]</td>\n",
       "      <td>23</td>\n",
       "      <td>0.324998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "      <td>[0, 1039, 673, 119, 5107, 25786, 40237, 46116, 197, 33, 56, 849, 29, 9636, 16836, 23, 5, 253, 2]</td>\n",
       "      <td>19</td>\n",
       "      <td>0.228498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "      <td>[0, 30327, 2283, 13, 209, 94, 367, 360, 9, 334, 8, 960, 14, 16, 164, 7, 28, 528, 328, 849, 29, 9636, 16836, 2]</td>\n",
       "      <td>24</td>\n",
       "      <td>0.295919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      3   \n",
       "3      4   \n",
       "4      4   \n",
       "\n",
       "                                                                                                                          text  \\\n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT   \n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony   \n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not   \n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end   \n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm   \n",
       "\n",
       "                                                                                                                                                  tokens  \\\n",
       "0  [0, 100, 95, 657, 447, 13, 231, 4, 245, 722, 396, 10, 1108, 50, 932, 4, 17570, 77, 38, 437, 15, 127, 675, 8, 33, 11522, 3977, 9782, 4, 849, 37049, 2]   \n",
       "1                                               [0, 133, 1372, 2214, 473, 45, 32550, 205, 6453, 4, 85, 18, 888, 1341, 2778, 19887, 4, 849, 853, 6119, 2]   \n",
       "2                                                    [0, 15852, 7, 422, 7, 5, 2341, 78, 631, 11, 5, 662, 16, 10, 372, 169, 7, 386, 5, 183, 849, 3654, 2]   \n",
       "3                                                       [0, 1039, 673, 119, 5107, 25786, 40237, 46116, 197, 33, 56, 849, 29, 9636, 16836, 23, 5, 253, 2]   \n",
       "4                                         [0, 30327, 2283, 13, 209, 94, 367, 360, 9, 334, 8, 960, 14, 16, 164, 7, 28, 528, 328, 849, 29, 9636, 16836, 2]   \n",
       "\n",
       "   n_tok  teacher_labels  \n",
       "0     32        0.070710  \n",
       "1     21        0.402885  \n",
       "2     23        0.324998  \n",
       "3     19        0.228498  \n",
       "4     24        0.295919  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "      <th>teacher_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED</td>\n",
       "      <td>[0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]</td>\n",
       "      <td>33</td>\n",
       "      <td>0.070710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm</td>\n",
       "      <td>[0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]</td>\n",
       "      <td>31</td>\n",
       "      <td>0.402885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT</td>\n",
       "      <td>[0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]</td>\n",
       "      <td>43</td>\n",
       "      <td>0.324998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>@stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not</td>\n",
       "      <td>[0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]</td>\n",
       "      <td>22</td>\n",
       "      <td>0.228498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!</td>\n",
       "      <td>[0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.295919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      2   \n",
       "1      3   \n",
       "2      2   \n",
       "3      2   \n",
       "4      5   \n",
       "\n",
       "                                                                                                                                          text  \\\n",
       "0                          So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED   \n",
       "1                          If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm   \n",
       "2  @KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT   \n",
       "3                                                              @stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not   \n",
       "4                                                    Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!   \n",
       "\n",
       "                                                                                                                                                                                                                                     tokens  \\\n",
       "0                                                                     [0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]   \n",
       "1                                                                              [0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]   \n",
       "2  [0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]   \n",
       "3                                                                                                                         [0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]   \n",
       "4                                                                [0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]   \n",
       "\n",
       "   n_tok  teacher_labels  \n",
       "0     33        0.070710  \n",
       "1     31        0.402885  \n",
       "2     43        0.324998  \n",
       "3     22        0.228498  \n",
       "4     32        0.295919  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds_sentiment:\n",
    "    def __init__ (self,df,bs,padlen=64,xvar='tokens',yvar='label',len_var='n_tok',y_teach='teacher_labels',padding_idx=1):\n",
    "        self.x=df[xvar]\n",
    "        self.y=df[yvar]\n",
    "        self.y_teach=df[y_teach]\n",
    "        self.padlen=padlen\n",
    "        self.padding_idx=padding_idx\n",
    "        self.len_var=df[len_var]\n",
    "        self.bs=bs\n",
    "    \n",
    "        self.len_var=self.len_var.clip(0,padlen)\n",
    "    \n",
    "    def pad (self,x):\n",
    "        out=np.ones(self.padlen)*self.padding_idx\n",
    "        out=out.astype(np.int64)\n",
    "        if len(x)>=self.padlen:\n",
    "            out[:]=x[:self.padlen]\n",
    "        else:\n",
    "            out[:len(x)]=x\n",
    "        return out\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        return self.pad(self.x.iloc[idx]),self.y.iloc[idx],self.len_var.iloc[idx],self.y_teach.iloc[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8577.000000\n",
       "mean       29.039408\n",
       "std         9.143004\n",
       "min         8.000000\n",
       "25%        22.000000\n",
       "50%        28.000000\n",
       "75%        35.000000\n",
       "max        50.000000\n",
       "Name: n_tok, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 10\n",
    "bptt= 70\n",
    "padlen = 50\n",
    "\n",
    "df_train.loc[df_train['n_tok'] > padlen, ['n_tok']] = padlen\n",
    "df_valid.loc[df_valid['n_tok'] > padlen, ['n_tok']] = padlen\n",
    "\n",
    "df_train['n_tok'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=ds_sentiment(df_train,bs,padlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvalid=ds_sentiment(df_valid,bs,padlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltrain = DataLoader(dstrain,bs,True)\n",
    "dlvalid = DataLoader(dsvalid,bs,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb,yb,xlen,yb_teach in dltrain:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0, 37739,   631,    47,    64,  2662,    89,     8,   486,   162,\n",
       "             10, 48391,     8,    10, 32594,     8,    45,   120,    11,  3605,\n",
       "             13,    24,     4,   849,  7199,     2,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  1039, 14009, 46994,  1790,  1215,  3383,  5818,  8425,    34,\n",
       "             57,  3610, 12711,    13,  2358,  9930,     4,   849,   853,  6119,\n",
       "              2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,   417,  4352,   787,  9772, 31777,   463,  3119,   141,   222,\n",
       "           1717,   283,    62,    19,    42,  6967,  6427,   116,   849,    29,\n",
       "           9636, 16836,  2054,   640,    90,     4,   876,    73,   574,   462,\n",
       "           1301,   705,  8272,   560,   846,  1000,     2,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0, 13963,   787,   863,  7405,  1180,   268, 12706,    35,  1801,\n",
       "           3996,    10,  1816, 20011,   160,    69, 16596,    71,  6614,    24,\n",
       "             15,     5,  1255,   137,  2057,    24,     7,    69, 14638,     4,\n",
       "            849,   853,  6119,   116,     2,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0, 27847,  1268,  4883,    14,     5,   787,   500,  4113, 34164,\n",
       "           3512,    32,     5,   200,  2373,   165,    11,     5,  6019,     4,\n",
       "            849, 10988, 25166,   116,   849,  3654,     2,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,   100,   348,    57,   608,     5,   276,  2125,     9,   173,\n",
       "             13,   130,   360,   122,  7586,   407,  7958,   849,  3654,     2,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  1039, 35238,  1116,   417, 28867,  1009,  6486,   607,    12,\n",
       "          19347,  2236,  3226,  2067,     6,    98,   222,    47,     6,   101,\n",
       "              6,   109,    24,    19,   784,  7480,   116, 17841,  9264,   849,\n",
       "             29,  9636, 16836,   784,  1916,   139,     2,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  7516, 26388,    95,   300,    88,   127,  3366,   334,   849,\n",
       "             29,  9636, 16836,  2054,   640,    90,     4,   876,    73,   267,\n",
       "          32880,   565,  1301,   347, 16593, 17357,     2,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  1779,    47,   214,    23,     5,  2003,     8,    47,   214,\n",
       "           1441,    34, 28657,   849,  1584, 38297,   849, 36741,   849,  3654,\n",
       "              2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,   100,  4157,   562,   341,     7,    86,  2056,  1022,   849,\n",
       "           3654, 44128,   282, 10431,   487,  8064,   996, 26795,  2403,   261,\n",
       "              2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1]]),\n",
       " tensor([1, 2, 3, 1, 3, 2, 4, 3, 3, 3]),\n",
       " tensor([26, 21, 37, 35, 27, 20, 37, 27, 21, 21]),\n",
       " tensor([0.2689, 0.8038, 0.5595, 0.3695, 0.3381, 0.5244, 0.3284, 0.1409, 0.3984,\n",
       "         0.6642], dtype=torch.float64))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb, xlen, yb_teach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_emb=768 #650\n",
    "n_hidden=64 #400\n",
    "n_layers= 2 # 2\n",
    "dropout=0.1 # 0.5\n",
    "wd=1e-5\n",
    "bidirectional=True\n",
    "dropout_e=0.2 # 0.5 - changing to 0.4, 0.3 or any dropout value did not make much difference\n",
    "dropout_o=0.1 #0.5\n",
    "n_out=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "class student_classifier (nn.Module):\n",
    "    def __init__(self,roberta_model,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,n_out=11,n_filters=100,filter_sizes=[3,4,5]):\n",
    "        super().__init__()\n",
    "        self.roberta_model,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device=\\\n",
    "                            roberta_model,n_emb,n_hidden,n_layers,bidirectional,bs,device\n",
    "        self.n_out,self.n_filters,self.filter_sizes=n_out,n_filters,filter_sizes\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "        \n",
    "        self.create_architecture()\n",
    "        self.init_hidden()\n",
    "        self.criterion=nn.CrossEntropyLoss()\n",
    "        self.distil_criterion=nn.MSELoss()\n",
    "    \n",
    "    def set_dropouts(self, dropout, dropout_o, dropout_e):\n",
    "        self.dropout, self.dropout_o, self.dropout_e = dropout, dropout_o, dropout_e\n",
    "    \n",
    "    \n",
    "    def freeze_embedding(self):\n",
    "        \n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "         \n",
    "    def unfreeze_embedding(self):\n",
    "        \n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "    \n",
    "\n",
    "    def create_architecture(self):\n",
    "        \n",
    "        #self.dropout_enc = nn.Dropout(self.dropout_e)\n",
    "        self.encoder = self.roberta_model\n",
    "        \n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=self.bidirectional)\n",
    "        \n",
    "        # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "        #self.dropout_op = nn.Dropout(self.dropout_o)\n",
    "        \n",
    "        self.max_pool1d = torch.nn.MaxPool1d(50, stride=1)\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "\n",
    "        self.project = nn.Linear(896,64)\n",
    "        \n",
    "        self.fc = nn.Linear(64,self.n_out)\n",
    "        \n",
    "        self.paralel = nn.Linear(64,1)\n",
    "\n",
    "        \n",
    "    def forward (self,Xb,Yb,Xb_lengths,Yb_teach):\n",
    "        \n",
    "        ####RNN PORTION\n",
    "        roberta_out = self.encoder(Xb)\n",
    "        last_hidden_states = roberta_out.last_hidden_state\n",
    "        embs = last_hidden_states\n",
    "        #print('embs : ', embs.shape)\n",
    "        \n",
    "        \n",
    "        #packed_embs = pack_padded_sequence(embs,Xb_lengths.cpu(),batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        \n",
    "        lstm_out,(hidden,cell)=self.lstm(embs)\n",
    "        #print('lstm_out : ', lstm_out.shape)\n",
    "        \n",
    "        \n",
    "        #lstm_out,lengths=pad_packed_sequence(lstm_out,batch_first=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Concatenate\n",
    "        catted = torch.cat([embs.permute(0,2,1),lstm_out.permute(0,2,1)],dim=1)\n",
    "        #print('catted : ', catted.shape)\n",
    "        \n",
    "        \n",
    "        ## Pooling\n",
    "        max_pool = self.max_pool1d(catted)\n",
    "        #print('max_pool : ', max_pool.shape)\n",
    "        \n",
    "        \n",
    "        ## Project to latent vectors\n",
    "        latent = self.project(self.flat(max_pool))\n",
    "        #print('latent : ', latent.shape)\n",
    "        \n",
    "        \n",
    "        ## Reshape\n",
    "        #ok = max_pool.permute(0,2,1)\n",
    "        #ok = ok.reshape(ok.size(0),ok.size(1)*ok.size(2))\n",
    "        #print('ok : ', ok.shape)\n",
    "        \n",
    "        \n",
    "        #Final output\n",
    "        student_preds = self.fc(latent)\n",
    "        \n",
    "        distil_preds = torch.sigmoid(self.paralel(latent))\n",
    "        \n",
    "        distil_preds=torch.flatten(distil_preds)\n",
    "\n",
    "\n",
    "        student_loss = self.criterion(student_preds,Yb.contiguous().long().view(-1))\n",
    "        \n",
    "        distil_loss = self.distil_criterion(distil_preds,Yb_teach.contiguous().float().view(-1))\n",
    "        \n",
    "        \n",
    "        final_loss = student_loss + (10 * distil_loss)\n",
    "\n",
    "        \n",
    "        return student_preds,final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_multinomial(preds, actual, device=\"cpu\", cutoff=0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    ela=F.softmax(preds, dim=1)\n",
    "    preds=ela.max(1)[1]\n",
    "    correct=preds==actual \n",
    "    acc = correct.float().sum()/len(correct)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None,\\\n",
    "                 cycle_mult=0,lr_decay=1,wd_mult=1):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cycle_mult,self.lr_decay=cycle_mult,lr_decay\n",
    "        self.wd_mult=wd_mult\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            self.start_lr=param_group['lr']\n",
    "            self.start_wd=param_group['weight_decay']\n",
    "        self.wd=self.start_wd\n",
    "        self.lr=self.start_lr\n",
    "        self.n_epoch=0\n",
    "        self.lrs=[1e-2,5e-3,1e-4,5e-4]\n",
    "        self.preds,self.preds_valid,self.trainY,self.actual=[],[],[],[]\n",
    "        \n",
    "    def fit (self,Xb,Yb,Xlen,Yb_teach,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            \n",
    "        preds,loss=self.model(Xb,Yb,Xlen,Yb_teach)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "            acc=acc.item()\n",
    "            \n",
    "            \n",
    "            if mode_train:\n",
    "                self.trainY.append(Yb.view(-1))\n",
    "                self.preds.append(preds.data)\n",
    "            else:\n",
    "                self.actual.append(Yb.view(-1))\n",
    "                self.preds_valid.append(preds.data)\n",
    "\n",
    "            \n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            if 1==0:\n",
    "                lr =self.lrs[torch.randint(0,4,(1,))]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=loss.item()\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        self.model.init_hidden()\n",
    "        for Xb,Yb,Xlen,Yb_teach in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            Xlen=Xlen.to(self.device)\n",
    "            Yb_teach=Yb_teach.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc=self.fit(Xb,Yb,Xlen,Yb_teach,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  {epoch_acc/(k)}')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "\n",
    "     \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        \n",
    "        if self.cycle_mult > 0:\n",
    "            reset_cycle=self.cycle_mult\n",
    "        \n",
    "        for epoch in range(n_epochs):                \n",
    "\n",
    "            \n",
    "            loss,acc=self.run_epoch(dltrain,True)\n",
    "            lossv,accv=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss} Train Accuracy:{acc} Valid Loss:{lossv} Valid Accuracy:{accv}')\n",
    "        \n",
    "            if self.cycle_mult:\n",
    "                if self.n_epoch==reset_cycle:\n",
    "                    self.lr=self.start_lr\n",
    "                    #self.wd=self.start_wd\n",
    "                    reset_cycle=self.n_epoch+reset_cycle\n",
    "                else:\n",
    "                    self.lr*=(self.lr_decay**self.n_epoch)  \n",
    "                    if self.n_epoch>1:\n",
    "                        self.wd*=self.wd_mult\n",
    "            self.n_epoch+=1\n",
    "                \n",
    "                \n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr']=self.lr\n",
    "                #param_group['weight_decay']=self.wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment=student_classifier (roberta_model,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout,\\\n",
    "                 dropout_o,n_out=11)\n",
    "model_sentiment=model_sentiment.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 125,230,156 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model_sentiment):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_sentiment.parameters(),lr=2e-5, eps=1e-6, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(model_sentiment,optimizer,accuracy_multinomial,device,bptt,100,0.25,cycle_mult=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.lr_decay, learner.wd_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_sentiment.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.unfreeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.6435513949394226  0.792000013589859\n",
      "Batch:200 0.6806550830602646  0.7920000134408474\n",
      "Batch:300 0.6951992390553157  0.7833333457509677\n",
      "Batch:400 0.6953020272403956  0.7817500122636557\n",
      "Batch:500 0.7019372930526734  0.7782000122666359\n",
      "Batch:600 0.7063826923320691  0.7770000125964482\n",
      "Batch:700 0.7090279481879302  0.7755714412246432\n",
      "Batch:800 0.7144504949636757  0.7728750125691295\n",
      "Batch:100 2.628750319480896  0.4510000078380108\n",
      "Batch:200 3.269946138858795  0.3440000063553452\n",
      "Batch:300 3.387346389691035  0.326000005826354\n",
      "Epoch:0 Learning rate 2e-05 Weight Decay 1e-05 Train Loss:0.7172425285954298 Train Accuracy:0.7706460331008707 Valid Loss:3.3713995702941006 Valid Accuracy:0.3287157348422992\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the cosine similarity metric via Semeval's script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_3957_preprocessed.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>537651335752323073</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>great come back dorm find roommate rearranged thing sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538332513408937986</td>\n",
       "      <td>-2</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>jean howie neighbour mum wedding make whole day cause really like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538050779824025600</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>lol katie hopkins u talk shagging married men fort great person 2 point finger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>538017499724279809</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>qpr looked terrible yesterday ferdinand player</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>537958766910926848</td>\n",
       "      <td>0</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>next jamie foxx ft 2 chainz party party tune tweet u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  label category  \\\n",
       "0  537651335752323073     -3  sarcasm   \n",
       "1  538332513408937986     -2  sarcasm   \n",
       "2  538050779824025600     -3  sarcasm   \n",
       "3  538017499724279809     -3  sarcasm   \n",
       "4  537958766910926848      0  sarcasm   \n",
       "\n",
       "                                                                             text  \n",
       "0                       great come back dorm find roommate rearranged thing sweet  \n",
       "1               jean howie neighbour mum wedding make whole day cause really like  \n",
       "2  lol katie hopkins u talk shagging married men fort great person 2 point finger  \n",
       "3                                  qpr looked terrible yesterday ferdinand player  \n",
       "4                            next jamie foxx ft 2 chainz party party tune tweet u  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "      <th>teacher_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED</td>\n",
       "      <td>[0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]</td>\n",
       "      <td>33</td>\n",
       "      <td>0.070710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm</td>\n",
       "      <td>[0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]</td>\n",
       "      <td>31</td>\n",
       "      <td>0.402885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT</td>\n",
       "      <td>[0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]</td>\n",
       "      <td>43</td>\n",
       "      <td>0.324998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>@stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not</td>\n",
       "      <td>[0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]</td>\n",
       "      <td>22</td>\n",
       "      <td>0.228498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!</td>\n",
       "      <td>[0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.295919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      2   \n",
       "1      3   \n",
       "2      2   \n",
       "3      2   \n",
       "4      5   \n",
       "\n",
       "                                                                                                                                          text  \\\n",
       "0                          So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED   \n",
       "1                          If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm   \n",
       "2  @KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT   \n",
       "3                                                              @stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not   \n",
       "4                                                    Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!   \n",
       "\n",
       "                                                                                                                                                                                                                                     tokens  \\\n",
       "0                                                                     [0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]   \n",
       "1                                                                              [0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]   \n",
       "2  [0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]   \n",
       "3                                                                                                                         [0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]   \n",
       "4                                                                [0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]   \n",
       "\n",
       "   n_tok  teacher_labels  \n",
       "0     33        0.070710  \n",
       "1     31        0.402885  \n",
       "2     43        0.324998  \n",
       "3     22        0.228498  \n",
       "4     32        0.295919  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = df_test['label']+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    3957\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_test['label'] == df_valid['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3957, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_test['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catch up here to update the outputs while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_preds_valid = [item.max(1)[1] for item in learner.preds_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the outputs of our model for the test data\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "preds_valid=list(chain.from_iterable(proper_preds_valid))[-df_valid.shape[0]:]\n",
    "actual=list(chain.from_iterable(learner.actual))[-df_valid.shape[0]:]\n",
    "\n",
    "preds_valid=[x.item() for x in preds_valid]\n",
    "actual=[x.item() for x in actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "      <th>teacher_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED</td>\n",
       "      <td>[0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]</td>\n",
       "      <td>33</td>\n",
       "      <td>0.070710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm</td>\n",
       "      <td>[0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]</td>\n",
       "      <td>31</td>\n",
       "      <td>0.402885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT</td>\n",
       "      <td>[0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]</td>\n",
       "      <td>43</td>\n",
       "      <td>0.324998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>@stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not</td>\n",
       "      <td>[0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]</td>\n",
       "      <td>22</td>\n",
       "      <td>0.228498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!</td>\n",
       "      <td>[0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.295919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      2   \n",
       "1      3   \n",
       "2      2   \n",
       "3      2   \n",
       "4      5   \n",
       "\n",
       "                                                                                                                                          text  \\\n",
       "0                          So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED   \n",
       "1                          If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm   \n",
       "2  @KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT   \n",
       "3                                                              @stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not   \n",
       "4                                                    Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!   \n",
       "\n",
       "                                                                                                                                                                                                                                     tokens  \\\n",
       "0                                                                     [0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]   \n",
       "1                                                                              [0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]   \n",
       "2  [0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]   \n",
       "3                                                                                                                         [0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]   \n",
       "4                                                                [0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]   \n",
       "\n",
       "   n_tok  teacher_labels  \n",
       "0     33        0.070710  \n",
       "1     31        0.402885  \n",
       "2     43        0.324998  \n",
       "3     22        0.228498  \n",
       "4     32        0.295919  "
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds_valid = np.array(preds_valid)\n",
    "preds_valid = preds_valid - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_model_test_outputs = pd.DataFrame()\n",
    "my_model_test_outputs['id'] = ids\n",
    "my_model_test_outputs['output'] = preds_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>537651335752323073</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538332513408937986</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538050779824025600</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>538017499724279809</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>537958766910926848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  output\n",
       "0  537651335752323073      -3\n",
       "1  538332513408937986      -2\n",
       "2  538050779824025600      -3\n",
       "3  538017499724279809      -3\n",
       "4  537958766910926848       0"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_test_outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_test_outputs.to_csv(\"exact_mse-150.tsv\", sep=\"\\t\", index=False)    #got cos = 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1635)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "input = torch.tensor(preds_valid)\n",
    "target = torch.tensor((df_test['label']-5).to_numpy())\n",
    "output = mse(input.float(), target.float())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBO_PATH = \"C:/Users/Dennis/Desktop/Distillation/novelty saves\"\n",
    "\n",
    "torch.save (roberta_model,f'{COMBO_PATH}/roberta_model')\n",
    "torch.save(model_sentiment.state_dict(),f'{COMBO_PATH}/model_sentiment_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{COMBO_PATH}/optimizer_state_dict')\n",
    "torch.save (model_sentiment,f'{COMBO_PATH}/model_sentiment')\n",
    "torch.save (optimizer,f'{COMBO_PATH}/optimizer')\n",
    "torch.save (learner,f'{COMBO_PATH}/learner')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
