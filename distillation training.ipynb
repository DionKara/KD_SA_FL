{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import os\n",
    "import fastai\n",
    "from fastai.text import *\n",
    "from fastai import *\n",
    "import regex as re\n",
    "import spacy\n",
    "from fastai.text.core import tokenize_texts \n",
    "import collections \n",
    "from collections import Counter\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the teacher (sarcasm model) and get predictions on S15-T11 to use them as ground truth for distillation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data\n",
    "\n",
    "df_train = pd.read_csv(\"train_8k.csv\")\n",
    "df_trial = pd.read_csv(\"trial_1k.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = ['old id', 'new id', 'label', 'int_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          text\n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT\n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony\n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not\n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end\n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>int_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465424601124974592</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>RT @BeckyMyers3: General studies exam tomorrow and I have about as much common sense and knowledge as a peanut</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>465422141643845632</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>RT @TheTweetOfGod: A racist NBA owner makes about as much sense as a homophobic theater producer.</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>465420676590231552</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>Bit ironic Mo Farrah stars in the Weetabix advert when he shares about as much personality as a semi chipped bowl filled with half of one</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465420343344394240</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>@JoshFreedman_ It is about as much an election than Katie Price was a singer.</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465414678978756609</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>Just looked out the window. About as inviting as a tour of Karbul. Today is that day i 'finally' polyfilled that hole in the bathroom! Brb</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  label  \\\n",
       "0  465424601124974592   -3.0   \n",
       "1  465422141643845632   -3.4   \n",
       "2  465420676590231552   -2.8   \n",
       "3  465420343344394240   -2.8   \n",
       "4  465414678978756609   -2.4   \n",
       "\n",
       "                                                                                                                                         text  \\\n",
       "0                              RT @BeckyMyers3: General studies exam tomorrow and I have about as much common sense and knowledge as a peanut   \n",
       "1                                           RT @TheTweetOfGod: A racist NBA owner makes about as much sense as a homophobic theater producer.   \n",
       "2   Bit ironic Mo Farrah stars in the Weetabix advert when he shares about as much personality as a semi chipped bowl filled with half of one   \n",
       "3                                                               @JoshFreedman_ It is about as much an election than Katie Price was a singer.   \n",
       "4  Just looked out the window. About as inviting as a tour of Karbul. Today is that day i 'finally' polyfilled that hole in the bathroom! Brb   \n",
       "\n",
       "   int_label  \n",
       "0         -3  \n",
       "1         -3  \n",
       "2         -3  \n",
       "3         -3  \n",
       "4         -2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df_trial.drop(columns = ['id', 'label', 'int_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7985, 1), (592, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_trial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, df_trial], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8577, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          text\n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT\n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony\n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not\n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end\n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess used from #1 kernel in kaggle for sentiment140 dataset\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "HASHTAG_CLEANING_RE = \"#\\S+\"\n",
    "MENTION_CLEANING_RE = \"@\\S+\"\n",
    "TEXT_CLEANING_RE = \"https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(text, lemma=True):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(HASHTAG_CLEANING_RE, ' ', str(text).lower())\n",
    "    text = re.sub(MENTION_CLEANING_RE, ' ', str(text).lower())\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words or token in ['not', 'can']:\n",
    "            if lemma:\n",
    "                tokens.append(lemmatizer.lemmatize(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df_train.text = df_train.text.apply(lambda x: preprocess(x))\n",
    "\n",
    "\n",
    "\n",
    "df_train.to_csv('preprocessed_tweets.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "BOS = \"xxbos\"\n",
    "FLD = \"xxfld\"\n",
    "\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n",
    "        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "def get_texts(df, n_lbls=0):\n",
    "\n",
    "    texts = f'\\n {FLD} 1 ' + df.iloc[:,n_lbls].astype(str)\n",
    "\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "\n",
    "\n",
    "    tokop = tokenize_texts(texts)\n",
    "    return tokop\n",
    "\n",
    "\n",
    "def get_all(df, n_lbls):\n",
    "    tok = []\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    for i, txt in enumerate(df):\n",
    "        tok_ = get_texts(txt, n_lbls)\n",
    "        tok += tok_\n",
    "    return tok\n",
    "\n",
    "\n",
    "chunksize = 24000\n",
    "chunk_tweets = pd.read_csv('preprocessed_tweets.csv',chunksize=chunksize)\n",
    "\n",
    "\n",
    "# the splitted words of each sentence (not numbers)\n",
    "tokens = get_all(chunk_tweets, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original vocab used for training\n",
    "[df_train_2,df_valid_2,itos, train_tokens_2, valid_tokens_2, trn_lm_2, val_lm_2] = pickle.load(open('teacher - Tweets with sarcasm and irony - Binary/dfs_tokens_fastai_NEW.pkl','rb'))\n",
    "\n",
    "\n",
    "# Recreate the dictionary used for training to ensure that we use same word indices as in training\n",
    "stoi = collections.defaultdict(lambda: 0, { v: k for k, v in enumerate(itos) })\n",
    "\n",
    "\n",
    "# recreate the sequences by replacing the words with their indices from the dictionary (stoi_1)\n",
    "lm = np.array([ [stoi[o] for o in p] for p in tokens ])\n",
    "\n",
    "# add a 'tokens' field in our dataframe with the tokenized sequences\n",
    "df_train['tokens'] = lm\n",
    "\n",
    "\n",
    "\n",
    "df_train['n_tok'] = df_train['tokens'].apply(len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love working 6 5 hour without break anything especially period awful cramp</td>\n",
       "      <td>[3, 4, 2, 10, 188, 147, 57, 103, 197, 335, 257, 928, 2251, 1308, 7378]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy song not invoke good feeling actually quite extremely annoying</td>\n",
       "      <td>[3, 4, 2, 117, 224, 1004, 0, 14, 307, 153, 719, 2472, 1705]</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run train first thing morning great way start day</td>\n",
       "      <td>[3, 4, 2, 164, 342, 52, 34, 99, 19, 36, 91, 9]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>haha end</td>\n",
       "      <td>[3, 4, 2, 291, 149]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really excited last day school everything going due</td>\n",
       "      <td>[3, 4, 2, 26, 388, 61, 9, 68, 191, 43, 635]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         text  \\\n",
       "0  love working 6 5 hour without break anything especially period awful cramp   \n",
       "1        happy song not invoke good feeling actually quite extremely annoying   \n",
       "2                           run train first thing morning great way start day   \n",
       "3                                                                    haha end   \n",
       "4                         really excited last day school everything going due   \n",
       "\n",
       "                                                                   tokens  \\\n",
       "0  [3, 4, 2, 10, 188, 147, 57, 103, 197, 335, 257, 928, 2251, 1308, 7378]   \n",
       "1             [3, 4, 2, 117, 224, 1004, 0, 14, 307, 153, 719, 2472, 1705]   \n",
       "2                          [3, 4, 2, 164, 342, 52, 34, 99, 19, 36, 91, 9]   \n",
       "3                                                     [3, 4, 2, 291, 149]   \n",
       "4                             [3, 4, 2, 26, 388, 61, 9, 68, 191, 43, 635]   \n",
       "\n",
       "   n_tok  \n",
       "0     15  \n",
       "1     13  \n",
       "2     12  \n",
       "3      5  \n",
       "4     11  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the sequences to have same length input tweets\n",
    "padlen=33 #use the same padlen as in training \n",
    "padding_idx=1\n",
    "\n",
    "def pad (x, padlen, padding_idx):\n",
    "    out=np.ones(padlen)*padding_idx\n",
    "    out=out.astype(np.int64)\n",
    "    if len(x)>=padlen:\n",
    "        out[:]=x[:padlen]\n",
    "    else:\n",
    "        out[:len(x)]=x\n",
    "    return out\n",
    "\n",
    "df_train.tokens = df_train.tokens.apply(lambda x: pad(x, padlen, padding_idx))\n",
    "\n",
    "\n",
    "df_train.loc[df_train['n_tok'] > padlen, ['n_tok']] = padlen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must define model's class first , to be able to load it.\n",
    "\n",
    "n_inp=len(itos)\n",
    "n_emb=200 #650\n",
    "n_hidden=200#400\n",
    "n_layers= 2 # 2\n",
    "dropout=0.5 # 0.5\n",
    "wd=1e-7\n",
    "bidirectional=True\n",
    "dropout_e=0.2 # 0.5 - changing to 0.4, 0.3 or any dropout value did not make much difference\n",
    "dropout_o=0.5 #0.5\n",
    "n_out=1\n",
    "\n",
    "\n",
    "class sentiment_classifier (nn.Module):\n",
    "    def __init__(self,n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,pretrain_mtx=None,n_out=1,padding_idx=1,n_filters=100,filter_sizes=[3,4,5]):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device,self.pretrain_mtx,self.padding_idx=\\\n",
    "                            n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,pretrain_mtx,padding_idx\n",
    "        self.n_out,self.n_filters,self.filter_sizes=n_out,n_filters,filter_sizes\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "\n",
    "        self.create_architecture()\n",
    "        if pretrain_mtx is not None:\n",
    "            print (f'initializing glove with {pretrain_mtx.shape}')\n",
    "            self.initialize_glove()\n",
    "        self.init_hidden()\n",
    "        self.criterion=nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def set_dropouts(self, dropout, dropout_o, dropout_e):\n",
    "        self.dropout, self.dropout_o, self.dropout_e = dropout, dropout_o, dropout_e\n",
    "\n",
    "\n",
    "    def freeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=False\n",
    "\n",
    "    def unfreeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=True\n",
    "\n",
    "    def initialize_glove(self):\n",
    "        self.encoder.weight.data.copy_(torch.Tensor(self.pretrain_mtx))\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "\n",
    "\n",
    "    def create_architecture(self):\n",
    "        ###################################\n",
    "        # Embedding layer - common to both\n",
    "        ###################################\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb,padding_idx=self.padding_idx)\n",
    "\n",
    "        #######################################\n",
    "        # For RNN #############################\n",
    "        #######################################\n",
    "        # Embedding Layer: Embedding layer just maps each word to an index. n_inp to n_emb mapping is all it does\n",
    "            # input to this is of shape n_batch * n_seq\n",
    "         # LSTM Layer\n",
    "        self.lstm=nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=self.bidirectional)\n",
    "          # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "\n",
    "        self.avg_pool1d=torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool1d=torch.nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "\n",
    "        #######################################\n",
    "        # For CNN #############################\n",
    "        #######################################    \n",
    "        #embedding dimension is the \"depth\" of the filter and the number of tokens in the sentence is the width.\n",
    "        self.conv_0=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[0])\n",
    "        self.conv_1=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[1])\n",
    "        self.conv_2=torch.nn.Conv1d(self.n_emb,self.n_filters,kernel_size=self.filter_sizes[2])\n",
    "\n",
    "        self.fc=nn.Linear(len(self.filter_sizes)*self.n_filters+self.n_hidden*4,self.n_out)\n",
    "\n",
    "\n",
    "\n",
    "    def forward (self,Xb,Xb_lengths):\n",
    "\n",
    "        ####RNN PORTION\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "        if Xb.size(0) < self.bs:\n",
    "            self.hidden=(self.hidden[0][:,:Xb.size(0),:].contiguous(),\n",
    "            self.hidden[1][:,:Xb.size(0),:].contiguous())\n",
    "        packed_embs = pack_padded_sequence(embs,Xb_lengths.cpu(),batch_first=True, enforce_sorted=False)\n",
    "        lstm_out,(hidden,cell)=self.lstm(packed_embs)\n",
    "        lstm_out,lengths=pad_packed_sequence(lstm_out,batch_first=True)\n",
    "        hidden = self.dropout_op(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        avg_pool=self.avg_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        max_pool=self.max_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "\n",
    "        #CNN Portion\n",
    "        new_embs=embs.permute(0,2,1)        \n",
    "        conved_0=torch.relu(self.conv_0(new_embs))\n",
    "        conved_1=torch.relu(self.conv_1(new_embs))\n",
    "        conved_2=torch.relu(self.conv_2(new_embs)) \n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_0.shape[2])\n",
    "        pooled_0=max_pool1d(conved_0).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_1.shape[2])\n",
    "        pooled_1=max_pool1d(conved_1).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_2.shape[2])\n",
    "        pooled_2=max_pool1d(conved_2).squeeze(2)\n",
    "        cat_cnn = self.dropout_op(torch.cat([pooled_0,pooled_1,pooled_2],dim=1))\n",
    "\n",
    "        ## Concatenate\n",
    "        big_out=torch.cat([cat_cnn,hidden,max_pool],dim=1)\n",
    "        preds=self.fc(big_out)\n",
    "\n",
    "        preds = torch.sigmoid(preds.view(-1))\n",
    "\n",
    "\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, chunk_size = 100): \n",
    "        chunks = list()\n",
    "        num_chunks = len(df) // chunk_size + 1\n",
    "        for i in range(num_chunks):\n",
    "            chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "        return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "COMBO_PATH = \"teacher - Tweets with sarcasm and irony - Binary/tuned saves\"\n",
    "\n",
    "model_sentiment = torch.load (f'{COMBO_PATH}/model_sentiment')\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model_sentiment = model_sentiment.to(device)\n",
    "\n",
    "\n",
    "iterable = split_dataframe(df_train)\n",
    "\n",
    "\n",
    "# Get predictions on our new data\n",
    "\n",
    "y_pred_teacher = np.zeros(df_train.shape[0])\n",
    "k=0\n",
    "\n",
    "for data in iterable:\n",
    "    data = data.reset_index(drop=True)\n",
    "    x = data['tokens']\n",
    "    x_len = data['n_tok']\n",
    "\n",
    "    x = torch.tensor(x)\n",
    "    x_len = torch.tensor(x_len)\n",
    "\n",
    "    x = x.to(device)\n",
    "    x_len = x_len.to(device)\n",
    "\n",
    "    y_pred = model_sentiment(x, x_len)\n",
    "\n",
    "    y_pred = y_pred.to(\"cpu\")\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "\n",
    "    y_pred_teacher[k:k+100] = y_pred\n",
    "    k+=100\n",
    "\n",
    "    del x\n",
    "    del x_len\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07070994, 0.40288487, 0.32499784, ..., 0.11287053, 0.16063896,\n",
       "       0.1547837 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('teacher_labels.csv', y_pred_teacher, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start distillation from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the teacher ground truth (used for distillation loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_labels = np.loadtxt('teacher_labels.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07070994, 0.40288487, 0.32499784, ..., 0.11287053, 0.16063896,\n",
       "       0.1547837 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the student for training (potamias model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the roberta tokenizer and model \n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\"\n",
    "roberta_model = roberta_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"train_8k.csv\")\n",
    "df_valid = pd.read_csv(\"test_4k.csv\")\n",
    "df_trial = pd.read_csv(\"trial_1k.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old id</th>\n",
       "      <th>new id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>int_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>472189928340606976</td>\n",
       "      <td>519632796449378304</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472440774785650688</td>\n",
       "      <td>519632825167773696</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473085653454827520</td>\n",
       "      <td>519632853982650370</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>463445012374499328</td>\n",
       "      <td>519632882940129280</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>463501257110724610</td>\n",
       "      <td>519632911473987584</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               old id              new id  label  \\\n",
       "0  472189928340606976  519632796449378304  -3.99   \n",
       "1  472440774785650688  519632825167773696  -3.92   \n",
       "2  473085653454827520  519632853982650370  -2.22   \n",
       "3  463445012374499328  519632882940129280  -0.56   \n",
       "4  463501257110724610  519632911473987584  -1.27   \n",
       "\n",
       "                                                                                                                          text  \\\n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT   \n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony   \n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not   \n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end   \n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm   \n",
       "\n",
       "   int_label  \n",
       "0         -4  \n",
       "1         -4  \n",
       "2         -2  \n",
       "3         -1  \n",
       "4         -1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7985, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = ['old id', 'new id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3    2966\n",
       "-2    2931\n",
       "-1     860\n",
       "-4     363\n",
       " 0     344\n",
       " 2     195\n",
       " 1     163\n",
       " 3     106\n",
       " 4      49\n",
       "-5       6\n",
       " 5       2\n",
       "Name: int_label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['int_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns={'int_label': 'label'}, inplace=True)\n",
    "df_train = df_train[[\"label\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4</td>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4</td>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2</td>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0     -4   \n",
       "1     -4   \n",
       "2     -2   \n",
       "3     -1   \n",
       "4     -1   \n",
       "\n",
       "                                                                                                                          text  \n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT  \n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony  \n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not  \n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end  \n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.376513e+17</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.383325e+17</td>\n",
       "      <td>-2</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.380508e+17</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>@KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.380175e+17</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>@stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.379588e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  label category  \\\n",
       "0  5.376513e+17     -3  sarcasm   \n",
       "1  5.383325e+17     -2  sarcasm   \n",
       "2  5.380508e+17     -3  sarcasm   \n",
       "3  5.380175e+17     -3  sarcasm   \n",
       "4  5.379588e+17      0  sarcasm   \n",
       "\n",
       "                                                                                                                                          text  \n",
       "0                          So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED  \n",
       "1                          If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm  \n",
       "2  @KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT  \n",
       "3                                                              @stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not  \n",
       "4                                                    Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = df_valid.drop(columns = ['id', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>int_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465424601124974592</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>RT @BeckyMyers3: General studies exam tomorrow and I have about as much common sense and knowledge as a peanut</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>465422141643845632</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>RT @TheTweetOfGod: A racist NBA owner makes about as much sense as a homophobic theater producer.</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>465420676590231552</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>Bit ironic Mo Farrah stars in the Weetabix advert when he shares about as much personality as a semi chipped bowl filled with half of one</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465420343344394240</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>@JoshFreedman_ It is about as much an election than Katie Price was a singer.</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465414678978756609</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>Just looked out the window. About as inviting as a tour of Karbul. Today is that day i 'finally' polyfilled that hole in the bathroom! Brb</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  label  \\\n",
       "0  465424601124974592   -3.0   \n",
       "1  465422141643845632   -3.4   \n",
       "2  465420676590231552   -2.8   \n",
       "3  465420343344394240   -2.8   \n",
       "4  465414678978756609   -2.4   \n",
       "\n",
       "                                                                                                                                         text  \\\n",
       "0                              RT @BeckyMyers3: General studies exam tomorrow and I have about as much common sense and knowledge as a peanut   \n",
       "1                                           RT @TheTweetOfGod: A racist NBA owner makes about as much sense as a homophobic theater producer.   \n",
       "2   Bit ironic Mo Farrah stars in the Weetabix advert when he shares about as much personality as a semi chipped bowl filled with half of one   \n",
       "3                                                               @JoshFreedman_ It is about as much an election than Katie Price was a singer.   \n",
       "4  Just looked out the window. About as inviting as a tour of Karbul. Today is that day i 'finally' polyfilled that hole in the bathroom! Brb   \n",
       "\n",
       "   int_label  \n",
       "0         -3  \n",
       "1         -3  \n",
       "2         -3  \n",
       "3         -3  \n",
       "4         -2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df_trial.drop(columns = ['id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial.rename(columns={'int_label': 'label'}, inplace=True)\n",
    "df_trial = df_trial[[\"label\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7985, 2), (592, 2), (3957, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_trial.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, df_trial], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8577, 2), (3957, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4</td>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4</td>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2</td>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0     -4   \n",
       "1     -4   \n",
       "2     -2   \n",
       "3     -1   \n",
       "4     -1   \n",
       "\n",
       "                                                                                                                          text  \n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT  \n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony  \n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not  \n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end  \n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3</td>\n",
       "      <td>So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2</td>\n",
       "      <td>If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3</td>\n",
       "      <td>@KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3</td>\n",
       "      <td>@stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0     -3   \n",
       "1     -2   \n",
       "2     -3   \n",
       "3     -3   \n",
       "4      0   \n",
       "\n",
       "                                                                                                                                          text  \n",
       "0                          So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED  \n",
       "1                          If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm  \n",
       "2  @KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT  \n",
       "3                                                              @stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not  \n",
       "4                                                    Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "myle = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = myle.fit_transform(df_train['label'])\n",
    "\n",
    "df_valid['label'] = myle.fit_transform(df_valid['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     3191\n",
       "3     3067\n",
       "4      925\n",
       "1      410\n",
       "5      377\n",
       "7      218\n",
       "6      196\n",
       "8      126\n",
       "9       56\n",
       "0        8\n",
       "10       3\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     1530\n",
       "2      730\n",
       "4      671\n",
       "5      293\n",
       "8      201\n",
       "6      164\n",
       "7      150\n",
       "9      111\n",
       "1       99\n",
       "10       4\n",
       "0        4\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = df_train['text']\n",
    "tweets_valid = df_valid['text']\n",
    "\n",
    "tweets_train = tweets_train.tolist()\n",
    "tweets_valid = tweets_valid.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenizer(tweets_train, truncation=True)\n",
    "tokens_valid = tokenizer(tweets_valid, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tokens'] = tokens_train['input_ids']\n",
    "df_valid['tokens'] = tokens_valid['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8577.000000\n",
       "mean       29.213361\n",
       "std        10.932552\n",
       "min         8.000000\n",
       "25%        22.000000\n",
       "50%        28.000000\n",
       "75%        35.000000\n",
       "max       512.000000\n",
       "Name: n_tok, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['n_tok'] = df_train['tokens'].apply(len)\n",
    "df_valid['n_tok'] = df_valid['tokens'].apply(len)\n",
    "\n",
    "df_train['n_tok'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "      <td>[0, 100, 95, 657, 447, 13, 231, 4, 245, 722, 396, 10, 1108, 50, 932, 4, 17570, 77, 38, 437, 15, 127, 675, 8, 33, 11522, 3977, 9782, 4, 849, 37049, 2]</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "      <td>[0, 133, 1372, 2214, 473, 45, 32550, 205, 6453, 4, 85, 18, 888, 1341, 2778, 19887, 4, 849, 853, 6119, 2]</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "      <td>[0, 15852, 7, 422, 7, 5, 2341, 78, 631, 11, 5, 662, 16, 10, 372, 169, 7, 386, 5, 183, 849, 3654, 2]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "      <td>[0, 1039, 673, 119, 5107, 25786, 40237, 46116, 197, 33, 56, 849, 29, 9636, 16836, 23, 5, 253, 2]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "      <td>[0, 30327, 2283, 13, 209, 94, 367, 360, 9, 334, 8, 960, 14, 16, 164, 7, 28, 528, 328, 849, 29, 9636, 16836, 2]</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      3   \n",
       "3      4   \n",
       "4      4   \n",
       "\n",
       "                                                                                                                          text  \\\n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT   \n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony   \n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not   \n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end   \n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm   \n",
       "\n",
       "                                                                                                                                                  tokens  \\\n",
       "0  [0, 100, 95, 657, 447, 13, 231, 4, 245, 722, 396, 10, 1108, 50, 932, 4, 17570, 77, 38, 437, 15, 127, 675, 8, 33, 11522, 3977, 9782, 4, 849, 37049, 2]   \n",
       "1                                               [0, 133, 1372, 2214, 473, 45, 32550, 205, 6453, 4, 85, 18, 888, 1341, 2778, 19887, 4, 849, 853, 6119, 2]   \n",
       "2                                                    [0, 15852, 7, 422, 7, 5, 2341, 78, 631, 11, 5, 662, 16, 10, 372, 169, 7, 386, 5, 183, 849, 3654, 2]   \n",
       "3                                                       [0, 1039, 673, 119, 5107, 25786, 40237, 46116, 197, 33, 56, 849, 29, 9636, 16836, 23, 5, 253, 2]   \n",
       "4                                         [0, 30327, 2283, 13, 209, 94, 367, 360, 9, 334, 8, 960, 14, 16, 164, 7, 28, 528, 328, 849, 29, 9636, 16836, 2]   \n",
       "\n",
       "   n_tok  \n",
       "0     32  \n",
       "1     21  \n",
       "2     23  \n",
       "3     19  \n",
       "4     24  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(teacher_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_labels = pd.Series(teacher_labels)\n",
    "\n",
    "df_train['teacher_labels'] = teacher_labels\n",
    "df_valid['teacher_labels'] = teacher_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "      <th>teacher_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT</td>\n",
       "      <td>[0, 100, 95, 657, 447, 13, 231, 4, 245, 722, 396, 10, 1108, 50, 932, 4, 17570, 77, 38, 437, 15, 127, 675, 8, 33, 11522, 3977, 9782, 4, 849, 37049, 2]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.070710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony</td>\n",
       "      <td>[0, 133, 1372, 2214, 473, 45, 32550, 205, 6453, 4, 85, 18, 888, 1341, 2778, 19887, 4, 849, 853, 6119, 2]</td>\n",
       "      <td>21</td>\n",
       "      <td>0.402885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Having to run to the train first thing in the morning is a great way to start the day #not</td>\n",
       "      <td>[0, 15852, 7, 422, 7, 5, 2341, 78, 631, 11, 5, 662, 16, 10, 372, 169, 7, 386, 5, 183, 849, 3654, 2]</td>\n",
       "      <td>23</td>\n",
       "      <td>0.324998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@OmniJerBear haha should have had #sarcasm at the end</td>\n",
       "      <td>[0, 1039, 673, 119, 5107, 25786, 40237, 46116, 197, 33, 56, 849, 29, 9636, 16836, 23, 5, 253, 2]</td>\n",
       "      <td>19</td>\n",
       "      <td>0.228498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Really excited for these last few days of school and everything that is going to be due! #sarcasm</td>\n",
       "      <td>[0, 30327, 2283, 13, 209, 94, 367, 360, 9, 334, 8, 960, 14, 16, 164, 7, 28, 528, 328, 849, 29, 9636, 16836, 2]</td>\n",
       "      <td>24</td>\n",
       "      <td>0.295919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      3   \n",
       "3      4   \n",
       "4      4   \n",
       "\n",
       "                                                                                                                          text  \\\n",
       "0  I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT   \n",
       "1                                 The happy song does not invoke good feelings. It's actually quite extremely annoying. #irony   \n",
       "2                                   Having to run to the train first thing in the morning is a great way to start the day #not   \n",
       "3                                                                        @OmniJerBear haha should have had #sarcasm at the end   \n",
       "4                            Really excited for these last few days of school and everything that is going to be due! #sarcasm   \n",
       "\n",
       "                                                                                                                                                  tokens  \\\n",
       "0  [0, 100, 95, 657, 447, 13, 231, 4, 245, 722, 396, 10, 1108, 50, 932, 4, 17570, 77, 38, 437, 15, 127, 675, 8, 33, 11522, 3977, 9782, 4, 849, 37049, 2]   \n",
       "1                                               [0, 133, 1372, 2214, 473, 45, 32550, 205, 6453, 4, 85, 18, 888, 1341, 2778, 19887, 4, 849, 853, 6119, 2]   \n",
       "2                                                    [0, 15852, 7, 422, 7, 5, 2341, 78, 631, 11, 5, 662, 16, 10, 372, 169, 7, 386, 5, 183, 849, 3654, 2]   \n",
       "3                                                       [0, 1039, 673, 119, 5107, 25786, 40237, 46116, 197, 33, 56, 849, 29, 9636, 16836, 23, 5, 253, 2]   \n",
       "4                                         [0, 30327, 2283, 13, 209, 94, 367, 360, 9, 334, 8, 960, 14, 16, 164, 7, 28, 528, 328, 849, 29, 9636, 16836, 2]   \n",
       "\n",
       "   n_tok  teacher_labels  \n",
       "0     32        0.070710  \n",
       "1     21        0.402885  \n",
       "2     23        0.324998  \n",
       "3     19        0.228498  \n",
       "4     24        0.295919  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I just love working for 6.5 hours without a break or anything. Especially when I'm on my period and have awful cramps. #NOT\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "      <th>teacher_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED</td>\n",
       "      <td>[0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]</td>\n",
       "      <td>33</td>\n",
       "      <td>0.070710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm</td>\n",
       "      <td>[0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]</td>\n",
       "      <td>31</td>\n",
       "      <td>0.402885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT</td>\n",
       "      <td>[0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]</td>\n",
       "      <td>43</td>\n",
       "      <td>0.324998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>@stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not</td>\n",
       "      <td>[0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]</td>\n",
       "      <td>22</td>\n",
       "      <td>0.228498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!</td>\n",
       "      <td>[0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.295919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      2   \n",
       "1      3   \n",
       "2      2   \n",
       "3      2   \n",
       "4      5   \n",
       "\n",
       "                                                                                                                                          text  \\\n",
       "0                          So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED   \n",
       "1                          If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm   \n",
       "2  @KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT   \n",
       "3                                                              @stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not   \n",
       "4                                                    Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!   \n",
       "\n",
       "                                                                                                                                                                                                                                     tokens  \\\n",
       "0                                                                     [0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]   \n",
       "1                                                                              [0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]   \n",
       "2  [0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]   \n",
       "3                                                                                                                         [0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]   \n",
       "4                                                                [0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]   \n",
       "\n",
       "   n_tok  teacher_labels  \n",
       "0     33        0.070710  \n",
       "1     31        0.402885  \n",
       "2     43        0.324998  \n",
       "3     22        0.228498  \n",
       "4     32        0.295919  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds_sentiment:\n",
    "    def __init__ (self,df,bs,padlen=64,xvar='tokens',yvar='label',len_var='n_tok',y_teach='teacher_labels',padding_idx=1):\n",
    "        self.x=df[xvar]\n",
    "        self.y=df[yvar]\n",
    "        self.y_teach=df[y_teach]\n",
    "        self.padlen=padlen\n",
    "        self.padding_idx=padding_idx\n",
    "        self.len_var=df[len_var]\n",
    "        self.bs=bs\n",
    "    \n",
    "        self.len_var=self.len_var.clip(0,padlen)\n",
    "    \n",
    "    def pad (self,x):\n",
    "        out=np.ones(self.padlen)*self.padding_idx\n",
    "        out=out.astype(np.int64)\n",
    "        if len(x)>=self.padlen:\n",
    "            out[:]=x[:self.padlen]\n",
    "        else:\n",
    "            out[:len(x)]=x\n",
    "        return out\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        return self.pad(self.x.iloc[idx]),self.y.iloc[idx],self.len_var.iloc[idx],self.y_teach.iloc[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8577.000000\n",
       "mean       29.039408\n",
       "std         9.143004\n",
       "min         8.000000\n",
       "25%        22.000000\n",
       "50%        28.000000\n",
       "75%        35.000000\n",
       "max        50.000000\n",
       "Name: n_tok, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 10\n",
    "bptt= 70\n",
    "padlen = 50\n",
    "\n",
    "df_train.loc[df_train['n_tok'] > padlen, ['n_tok']] = padlen\n",
    "df_valid.loc[df_valid['n_tok'] > padlen, ['n_tok']] = padlen\n",
    "\n",
    "df_train['n_tok'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=ds_sentiment(df_train,bs,padlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvalid=ds_sentiment(df_valid,bs,padlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltrain = DataLoader(dstrain,bs,True)\n",
    "dlvalid = DataLoader(dsvalid,bs,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb,yb,xlen,yb_teach in dltrain:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,  2527,   203,  1531,   849,    29,  9636, 16836,  2054,   640,\n",
       "             90,     4,   876,    73,   246,  4148,  3998,   530,    29,  1000,\n",
       "            530,   438,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,   534, 16037,   657,    77,    82,   283,    62,     8,  1137,\n",
       "             47,    59,   643,     4,   849,  3654,     2,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,   771,  4057,   216,   402,   116,    38,  4157,  7739,    13,\n",
       "          15734,     4,   849,  1193, 23145,   849,  3654,     2,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0, 43845, 20381, 14849,  1691, 20060,   221,   591,  2076, 12846,\n",
       "           6569,    27,  9357,  6569,    27, 14285,  2647,   938,    75,    14,\n",
       "             10,  1531,   618,  4126,   676, 12846, 18636, 25448,   849,  3654,\n",
       "              2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  1039, 14345,   787, 20142, 17875,  5949,   787, 22617,   352,\n",
       "           2590,   102,   281,   157,   114,  1268,  2215,    59,  3595,  2086,\n",
       "             63,   784, 10504,     6,    37,  1017,    28,    41,   849, 11515,\n",
       "           1571,     4, 28305,   123,     4,   849,  3654,   849, 37694,     2,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  3908,   475,  4926,  2980,  7051,   787,     5, 13885,   141,\n",
       "             64,    52,    45,   339,     5,   232,  4946,   116,   849,   853,\n",
       "           6119,   328,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  5096,     8,  2708,    33,     5,   275,  6620,   326,   571,\n",
       "            849,    29,  9636, 16836,     2,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0, 37967, 15313,  1258,    30, 37860,   163,  3450,    19,   468,\n",
       "           9504,  1075,    34,   669,     7,    10,  2783,  4378,  4083,    30,\n",
       "              5,   849,   119,  5715,     8,   849,   853,  6119,     9,   734,\n",
       "           2054,   640,    90,     4,   876,    73, 29159,  3764,   330, 42903,\n",
       "            510,  1301,   975,     2,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  2847,     6,    42,    16,    99,    24,  2653,   101,     7,\n",
       "             28,   504,   116,    38,   619,   734,   255,  7981,  2076,     4,\n",
       "            849,  3654,   849,  2629, 25518, 33272,  1208,     2,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0, 13963,   787, 20482,   104,  2560,  1725,    35,   787, 34836,\n",
       "          22197, 13643,   282,  2401,    24,    18,   142,    24,    18,  3013,\n",
       "             13,    82,     7,  1346,    10,  1686, 13816, 21705,   172,    10,\n",
       "           2182,  2048,     4,   849,    29,  9636, 16836,     2,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1]]),\n",
       " tensor([2, 3, 2, 3, 3, 3, 3, 2, 4, 3]),\n",
       " tensor([23, 17, 18, 31, 40, 23, 15, 44, 28, 38]),\n",
       " tensor([0.2230, 0.3031, 0.3492, 0.2037, 0.2836, 0.2377, 0.3375, 0.5414, 0.4325,\n",
       "         0.3504], dtype=torch.float64))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb, xlen, yb_teach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_emb=768 #650\n",
    "n_hidden=64 #400\n",
    "n_layers= 2 # 2\n",
    "dropout=0.1 # 0.5\n",
    "wd=1e-5\n",
    "bidirectional=True\n",
    "dropout_e=0.2 # 0.5 - changing to 0.4, 0.3 or any dropout value did not make much difference\n",
    "dropout_o=0.1 #0.5\n",
    "n_out=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class student_classifier (nn.Module):\n",
    "    def __init__(self,roberta_model,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,n_out=11,n_filters=100,filter_sizes=[3,4,5]):\n",
    "        super().__init__()\n",
    "        self.roberta_model,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device=\\\n",
    "                            roberta_model,n_emb,n_hidden,n_layers,bidirectional,bs,device\n",
    "        self.n_out,self.n_filters,self.filter_sizes=n_out,n_filters,filter_sizes\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "        \n",
    "        self.create_architecture()\n",
    "        self.init_hidden()\n",
    "        self.criterion=nn.CrossEntropyLoss()\n",
    "        self.distil_criterion=nn.MSELoss()\n",
    "    \n",
    "    def set_dropouts(self, dropout, dropout_o, dropout_e):\n",
    "        self.dropout, self.dropout_o, self.dropout_e = dropout, dropout_o, dropout_e\n",
    "    \n",
    "    \n",
    "    def freeze_embedding(self):\n",
    "        \n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "         \n",
    "    def unfreeze_embedding(self):\n",
    "        \n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "    \n",
    "\n",
    "    def create_architecture(self):\n",
    "        \n",
    "        #self.dropout_enc = nn.Dropout(self.dropout_e)\n",
    "        self.encoder = self.roberta_model\n",
    "        \n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=self.bidirectional)\n",
    "        \n",
    "        # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "        #self.dropout_op = nn.Dropout(self.dropout_o)\n",
    "        \n",
    "        self.max_pool1d = torch.nn.MaxPool1d(50, stride=1)\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "\n",
    "        self.project = nn.Linear(896,64)\n",
    "        \n",
    "        self.fc = nn.Linear(64,self.n_out)\n",
    "        \n",
    "        self.paralel = nn.Linear(64,1)\n",
    "\n",
    "        \n",
    "    def forward (self,Xb,Yb,Xb_lengths,Yb_teach):\n",
    "        \n",
    "        ####RNN PORTION\n",
    "        roberta_out = self.encoder(Xb)\n",
    "        last_hidden_states = roberta_out.last_hidden_state\n",
    "        embs = last_hidden_states\n",
    "        #print('embs : ', embs.shape)\n",
    "        \n",
    "        \n",
    "        #packed_embs = pack_padded_sequence(embs,Xb_lengths.cpu(),batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        \n",
    "        lstm_out,(hidden,cell)=self.lstm(embs)\n",
    "        #print('lstm_out : ', lstm_out.shape)\n",
    "        \n",
    "        \n",
    "        #lstm_out,lengths=pad_packed_sequence(lstm_out,batch_first=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Concatenate\n",
    "        catted = torch.cat([embs.permute(0,2,1),lstm_out.permute(0,2,1)],dim=1)\n",
    "        #print('catted : ', catted.shape)\n",
    "        \n",
    "        \n",
    "        ## Pooling\n",
    "        max_pool = self.max_pool1d(catted)\n",
    "        #print('max_pool : ', max_pool.shape)\n",
    "        \n",
    "        \n",
    "        ## Project to latent vectors\n",
    "        latent = self.project(self.flat(max_pool))\n",
    "        #print('latent : ', latent.shape)\n",
    "        \n",
    "        \n",
    "        ## Reshape\n",
    "        #ok = max_pool.permute(0,2,1)\n",
    "        #ok = ok.reshape(ok.size(0),ok.size(1)*ok.size(2))\n",
    "        #print('ok : ', ok.shape)\n",
    "        \n",
    "        \n",
    "        #Final output\n",
    "        student_preds = self.fc(latent)\n",
    "        \n",
    "        distil_preds = torch.sigmoid(self.paralel(latent))\n",
    "        \n",
    "        distil_preds=torch.flatten(distil_preds)\n",
    "\n",
    "\n",
    "        student_loss = self.criterion(student_preds,Yb.contiguous().long().view(-1))\n",
    "        \n",
    "        distil_loss = self.distil_criterion(distil_preds,Yb_teach.contiguous().float().view(-1))\n",
    "        \n",
    "        \n",
    "        final_loss = student_loss + distil_loss\n",
    "\n",
    "        \n",
    "        return student_preds,final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_multinomial(preds, actual, device=\"cpu\", cutoff=0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    ela=F.softmax(preds, dim=1)\n",
    "    preds=ela.max(1)[1]\n",
    "    correct=preds==actual \n",
    "    acc = correct.float().sum()/len(correct)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None,\\\n",
    "                 cycle_mult=0,lr_decay=1,wd_mult=1):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cycle_mult,self.lr_decay=cycle_mult,lr_decay\n",
    "        self.wd_mult=wd_mult\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            self.start_lr=param_group['lr']\n",
    "            self.start_wd=param_group['weight_decay']\n",
    "        self.wd=self.start_wd\n",
    "        self.lr=self.start_lr\n",
    "        self.n_epoch=0\n",
    "        self.lrs=[1e-2,5e-3,1e-4,5e-4]\n",
    "        self.preds,self.preds_valid,self.trainY,self.actual=[],[],[],[]\n",
    "        \n",
    "    def fit (self,Xb,Yb,Xlen,Yb_teach,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            \n",
    "        preds,loss=self.model(Xb,Yb,Xlen,Yb_teach)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "            acc=acc.item()\n",
    "            \n",
    "            \n",
    "            if mode_train:\n",
    "                self.trainY.append(Yb.view(-1))\n",
    "                self.preds.append(preds.data)\n",
    "            else:\n",
    "                self.actual.append(Yb.view(-1))\n",
    "                self.preds_valid.append(preds.data)\n",
    "\n",
    "            \n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            if 1==0:\n",
    "                lr =self.lrs[torch.randint(0,4,(1,))]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=loss.item()\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        self.model.init_hidden()\n",
    "        for Xb,Yb,Xlen,Yb_teach in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            Xlen=Xlen.to(self.device)\n",
    "            Yb_teach=Yb_teach.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc=self.fit(Xb,Yb,Xlen,Yb_teach,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  {epoch_acc/(k)}')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "\n",
    "     \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        \n",
    "        if self.cycle_mult > 0:\n",
    "            reset_cycle=self.cycle_mult\n",
    "        \n",
    "        for epoch in range(n_epochs):                \n",
    "\n",
    "            \n",
    "            loss,acc=self.run_epoch(dltrain,True)\n",
    "            lossv,accv=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss} Train Accuracy:{acc} Valid Loss:{lossv} Valid Accuracy:{accv}')\n",
    "        \n",
    "            if self.cycle_mult:\n",
    "                if self.n_epoch==reset_cycle:\n",
    "                    self.lr=self.start_lr\n",
    "                    #self.wd=self.start_wd\n",
    "                    reset_cycle=self.n_epoch+reset_cycle\n",
    "                else:\n",
    "                    self.lr*=(self.lr_decay**self.n_epoch)  \n",
    "                    if self.n_epoch>1:\n",
    "                        self.wd*=self.wd_mult\n",
    "            self.n_epoch+=1\n",
    "                \n",
    "                \n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr']=self.lr\n",
    "                #param_group['weight_decay']=self.wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment=student_classifier (roberta_model,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout,\\\n",
    "                 dropout_o,n_out=11)\n",
    "model_sentiment=model_sentiment.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 125,230,156 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model_sentiment):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_sentiment.parameters(),lr=2e-5, eps=1e-6, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(model_sentiment,optimizer,accuracy_multinomial,device,bptt,100,0.25,cycle_mult=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.lr_decay, learner.wd_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_sentiment.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_sentiment.unfreeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.6315232857316733  0.793000015616417\n",
      "Batch:200 0.6088467305526137  0.7930000133812427\n",
      "Batch:300 0.6209595644225677  0.7856666786472003\n",
      "Batch:400 0.6147455154173076  0.7907500125467777\n",
      "Batch:500 0.6262140686362981  0.7852000125646591\n",
      "Batch:600 0.6347145994131764  0.7820000124971072\n",
      "Batch:700 0.6363866459152528  0.7827142980269023\n",
      "Batch:800 0.6457234652619809  0.7765000122599304\n",
      "Batch:100 1.5428961971402169  0.49500000581145287\n",
      "Batch:200 1.9741957773268224  0.39000000566244125\n",
      "Batch:300 2.0591005207101505  0.36233333870768547\n",
      "Epoch:0 Learning rate 2e-05 Weight Decay 1e-05 Train Loss:0.6513372115651905 Train Accuracy:0.7737928862511972 Valid Loss:2.0752233863629477 Valid Accuracy:0.34931457987186887\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the cosine similarity metric via Semeval's script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_3957_preprocessed.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>537651335752323073</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>great come back dorm find roommate rearranged thing sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538332513408937986</td>\n",
       "      <td>-2</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>jean howie neighbour mum wedding make whole day cause really like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538050779824025600</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>lol katie hopkins u talk shagging married men fort great person 2 point finger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>538017499724279809</td>\n",
       "      <td>-3</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>qpr looked terrible yesterday ferdinand player</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>537958766910926848</td>\n",
       "      <td>0</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>next jamie foxx ft 2 chainz party party tune tweet u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  label category  \\\n",
       "0  537651335752323073     -3  sarcasm   \n",
       "1  538332513408937986     -2  sarcasm   \n",
       "2  538050779824025600     -3  sarcasm   \n",
       "3  538017499724279809     -3  sarcasm   \n",
       "4  537958766910926848      0  sarcasm   \n",
       "\n",
       "                                                                             text  \n",
       "0                       great come back dorm find roommate rearranged thing sweet  \n",
       "1               jean howie neighbour mum wedding make whole day cause really like  \n",
       "2  lol katie hopkins u talk shagging married men fort great person 2 point finger  \n",
       "3                                  qpr looked terrible yesterday ferdinand player  \n",
       "4                            next jamie foxx ft 2 chainz party party tune tweet u  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "      <th>teacher_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED</td>\n",
       "      <td>[0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]</td>\n",
       "      <td>33</td>\n",
       "      <td>0.070710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm</td>\n",
       "      <td>[0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]</td>\n",
       "      <td>31</td>\n",
       "      <td>0.402885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT</td>\n",
       "      <td>[0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]</td>\n",
       "      <td>43</td>\n",
       "      <td>0.324998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>@stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not</td>\n",
       "      <td>[0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]</td>\n",
       "      <td>22</td>\n",
       "      <td>0.228498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!</td>\n",
       "      <td>[0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.295919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      2   \n",
       "1      3   \n",
       "2      2   \n",
       "3      2   \n",
       "4      5   \n",
       "\n",
       "                                                                                                                                          text  \\\n",
       "0                          So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED   \n",
       "1                          If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm   \n",
       "2  @KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT   \n",
       "3                                                              @stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not   \n",
       "4                                                    Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!   \n",
       "\n",
       "                                                                                                                                                                                                                                     tokens  \\\n",
       "0                                                                     [0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]   \n",
       "1                                                                              [0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]   \n",
       "2  [0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]   \n",
       "3                                                                                                                         [0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]   \n",
       "4                                                                [0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]   \n",
       "\n",
       "   n_tok  teacher_labels  \n",
       "0     33        0.070710  \n",
       "1     31        0.402885  \n",
       "2     43        0.324998  \n",
       "3     22        0.228498  \n",
       "4     32        0.295919  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = df_test['label']+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    3957\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_test['label'] == df_valid['label']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3957, 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_test['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catch up here to update the outputs while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_preds_valid = [item.max(1)[1] for item in learner.preds_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the outputs of our model for the test data\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "preds_valid=list(chain.from_iterable(proper_preds_valid))[-df_valid.shape[0]:]\n",
    "actual=list(chain.from_iterable(learner.actual))[-df_valid.shape[0]:]\n",
    "\n",
    "preds_valid=[x.item() for x in preds_valid]\n",
    "actual=[x.item() for x in actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tok</th>\n",
       "      <th>teacher_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED</td>\n",
       "      <td>[0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]</td>\n",
       "      <td>33</td>\n",
       "      <td>0.070710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm</td>\n",
       "      <td>[0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]</td>\n",
       "      <td>31</td>\n",
       "      <td>0.402885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT</td>\n",
       "      <td>[0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]</td>\n",
       "      <td>43</td>\n",
       "      <td>0.324998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>@stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not</td>\n",
       "      <td>[0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]</td>\n",
       "      <td>22</td>\n",
       "      <td>0.228498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!</td>\n",
       "      <td>[0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.295919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      2   \n",
       "1      3   \n",
       "2      2   \n",
       "3      2   \n",
       "4      5   \n",
       "\n",
       "                                                                                                                                          text  \\\n",
       "0                          So great to come back to my dorm and find that my roommate rearranged my things for me. How sweet. #sarcasm #PISSED   \n",
       "1                          If jean howie my neighbour is at my mums wedding it will just make the whole day cause she really likes me #sarcasm   \n",
       "2  @KTHopkins @MissKatiePrice LOL@ katie hopkins u can talk, shagging married men is your forté isn't it? Great person 2 point the finger #NOT   \n",
       "3                                                              @stuarteagle QPR? They looked terrible yesterday. Ferdinand, what a player #Not   \n",
       "4                                                    Next! Jamie Foxx ft. 2 Chainz \"Party Ain't a Party\" - Tune in and Tweet us #HOT or #NOT!!   \n",
       "\n",
       "                                                                                                                                                                                                                                     tokens  \\\n",
       "0                                                                     [0, 2847, 372, 7, 283, 124, 7, 127, 18344, 8, 465, 14, 127, 25537, 37060, 17770, 127, 383, 13, 162, 4, 1336, 4045, 4, 849, 29, 9636, 16836, 849, 510, 17588, 1691, 2]   \n",
       "1                                                                              [0, 1106, 1236, 12001, 141, 324, 127, 14915, 16, 23, 127, 475, 8014, 3312, 24, 40, 95, 146, 5, 1086, 183, 1303, 79, 269, 3829, 162, 849, 29, 9636, 16836, 2]   \n",
       "2  [0, 1039, 530, 3732, 1517, 7327, 787, 22885, 27029, 324, 36677, 39687, 1039, 449, 415, 324, 13591, 7327, 1717, 64, 1067, 6, 1481, 12771, 2997, 604, 16, 110, 15016, 1140, 965, 75, 24, 116, 2860, 621, 132, 477, 5, 8411, 849, 37049, 2]   \n",
       "3                                                                                                                         [0, 1039, 620, 41962, 242, 21851, 1209, 4454, 116, 252, 1415, 6587, 2350, 4, 28855, 6, 99, 10, 869, 849, 7199, 2]   \n",
       "4                                                                [0, 19192, 328, 6541, 2063, 1178, 16935, 4, 132, 18610, 329, 22, 38210, 32431, 75, 10, 1643, 113, 111, 27879, 11, 8, 12244, 201, 849, 725, 3293, 50, 849, 37049, 12846, 2]   \n",
       "\n",
       "   n_tok  teacher_labels  \n",
       "0     33        0.070710  \n",
       "1     31        0.402885  \n",
       "2     43        0.324998  \n",
       "3     22        0.228498  \n",
       "4     32        0.295919  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds_valid = np.array(preds_valid)\n",
    "preds_valid = preds_valid - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_model_test_outputs = pd.DataFrame()\n",
    "my_model_test_outputs['id'] = ids\n",
    "my_model_test_outputs['output'] = preds_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>537651335752323073</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538332513408937986</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538050779824025600</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>538017499724279809</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>537958766910926848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  output\n",
       "0  537651335752323073      -3\n",
       "1  538332513408937986      -2\n",
       "2  538050779824025600      -2\n",
       "3  538017499724279809      -2\n",
       "4  537958766910926848       0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_test_outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_test_outputs.to_csv(\"exact_try.tsv\", sep=\"\\t\", index=False)    #got cos = 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5365)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "input = torch.tensor(preds_valid)\n",
    "target = torch.tensor((df_test['label']-5).to_numpy())\n",
    "output = mse(input.float(), target.float())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBO_PATH = \"C:/Users/Dennis/Desktop/Distillation/novelty saves\"\n",
    "\n",
    "torch.save (roberta_model,f'{COMBO_PATH}/roberta_model')\n",
    "torch.save(model_sentiment.state_dict(),f'{COMBO_PATH}/model_sentiment_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{COMBO_PATH}/optimizer_state_dict')\n",
    "torch.save (model_sentiment,f'{COMBO_PATH}/model_sentiment')\n",
    "torch.save (optimizer,f'{COMBO_PATH}/optimizer')\n",
    "torch.save (learner,f'{COMBO_PATH}/learner')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
